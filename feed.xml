<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://tarun360.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://tarun360.github.io/" rel="alternate" type="text/html" hreflang="en" /><updated>2023-12-15T16:41:15+00:00</updated><id>https://tarun360.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
</subtitle><entry><title type="html">Research directions</title><link href="https://tarun360.github.io/blog/2023/ai-research-directions/" rel="alternate" type="text/html" title="Research directions" /><published>2023-12-14T00:00:00+00:00</published><updated>2023-12-14T00:00:00+00:00</updated><id>https://tarun360.github.io/blog/2023/ai-research-directions</id><content type="html" xml:base="https://tarun360.github.io/blog/2023/ai-research-directions/"><![CDATA[<p>This blog is inspired by the question posed by Dr. Richard Hamming in his famous “You and Your Research” talk: “If what you are working on is not important, and it’s not likely to lead to important things, then why are you working on it?”</p>

<p>I have two specific directions in mind that I believe can lead to significant <i>things</i> in the field of AI (excluding applications in fields like medicine and biology): the first involves constructing a virtual playground for embodied multi-agent collaboration that can co-evolve into more intelligent agents, and the second focuses on building AI models that emulate the neural structures of the brain. I will briefly describe these two ideas below.</p>

<p><strong>Constructing a virtual playground for embodied multi-agent collaboration</strong></p>

<p>Exciting advancements have been made in constructing virtual playgrounds to investigate single-agent exploration [1] and multi-agent collaboration [2, 3]. The latter, as per my exploration, is less widely studied than the former. It is the latter that I believe holds more potential. These environments typically feature a leader agent and a follower agent working together to solve tasks. Leader-follower interactions can occur through various methods. For instance, the leader might issue instructions for a task, such as selecting a specific card from a set of distractor cards in the virtual environment, as in [2]. Subsequently, the follower is tasked with completing the assigned objective. Dialogue may transpire between the leader’s instructions and the follower’s actions. Notably, these instructions are typically communicated in a natural language, say English. These virtual environments are valuable for studying natural language interactions within collaborative and embodied environments.</p>

<p><i>I have an intuition, a vague idea, which I believe could advance the research on embodied multi-agent collaboration</i>, drawing inspiration from [2, 4, 5], and, to the best of my knowledge, unexplored thus far: Construct a virtual environment featuring a leader and a follower. The follower’s role is to observe the leader executing a task and intelligently imitate them. For instance, if the leader hides behind a tree to evade a lion, the follower should seek shelter behind an available object, like a large stone nearest to it, to avoid the lion. Blindly copying the leader, such as traveling to the leader’s position and attempting to hide behind the same small tree, could harm both.</p>

<p>Initially, the follower may adopt an approach akin to behavior parsing [6], employing a mechanistic imitation model, similar to ape behavior, based on statistical correlation without a deep understanding of the leader’s motives. However, as tasks become more difficult, there would be evolutionary pressure for the follower to develop a nuanced understanding of why a leader performs a specific task and determine the appropriate imitation variant, i.e., not copying the behavior blindly but copying the meaning of the behavior, i.e., the meme [5]. This necessitates creativity and the formulation of explanatory theories by the follower [4].</p>

<p>It would be advantageous for the follower to infer the leader’s mental state [7] (Theory of Mind) and generate explanatory theories about the reasons behind the leader’s actions and the contexts in which the follower should imitate them. Furthermore, in this virtual environment, communication between the leader and follower could be facilitated through some communication channel, such as exchanging arrays of bits. Since communication between the leader and follower would be helpful for the follower to understand the meme, it’s conceivable to imagine this array of bits transforming into a rudimentary sign language (emergent communication [8]).</p>

<p>This is just an intuitive direction that I think may lead to important discoveries. There is much to be figured out here; for example, the most difficult aspect would be how to design tasks which the leader agent is supposed to do, and the joint training of the leader and follower agent model. Perhaps, as a starting point one can consider crowdsourcing to generate the leader tasks, similar to [2], and then try to intelligently combine these tasks to generate more of them. Additionally, one would need to greatly improve the Theory of Mind idea so the follower can learn to model the leader’s worldview effectively. Lastly, constructing such a virtual environment would necessitate proficient game and software development skills.</p>

<p><strong>Building AI models that mimic the neural structures of the brain</strong></p>

<p>The present state of constructing increasingly complex machine learning architectures appears futile in creating a genuinely intelligent AI, or AGI. Merely combining different modalities blindly, such as outfitting a robot with vision, auditory, and text-understanding models, will not magically transform it into an intelligent agent. As articulated by Deutsch in [9], “Expecting to create an AGI without first understanding in detail how it works is like expecting skyscrapers to learn to fly if we build them tall enough.”</p>

<p>A more promising approach with a higher potential for AGI development would be to construct models inspired by the neural structures and geometries of the brain. Given that the brain inherently serves as an AGI, and with techniques such as fMRI, BOLD, and searchlight providing avenues for studying its internal structure, it is logical to examine the brain’s activity during diverse tasks. Subsequently, building AI models to replicate the observed neuronal structures during these tasks is a worthwhile strategy.</p>

<p>A noteworthy paper in this context is “Neural Knowledge Assembly in Humans and Neural Networks” [10]. This paper intrigued me due to the authors’ clever approach to testing a hypothesis (the elongation scheme) on rapid knowledge assembly in the human brain through a creative decision-making task performed by human participants. They monitored their brains’ dorsal stream structures using BOLD and searchlight techniques. Subsequently, the authors made a strikingly simple and elegant addition to a modest 2-layer neural network (a certainty matrix) to mimic the elongation scheme observed in human brains. In the current landscape of machine learning research, which often leans towards larger models, empirical fine-tuning, and explanation-less progress, it was invigorating to encounter a fundamental enhancement to a simple 2-layer neural network model inspired by knowledge assembly processes within the human brain.</p>

<p>Some other works include how speech aspects like context [11] and phonemes [12] impact neural structural representation. Understanding the representation structure of language in the human brain could aid in designing NLP models that emulate these structures, potentially resulting in improved NLP models similar to the approach taken in [10]. Overall, this fundamental research approach, where advancements in basic machine learning models are inspired by brain processes driven by conjecture and explanatory theories rather than solely increasing model complexity, is a worthwhile direction in pursuit of building better AI models.</p>

<p><strong>References</strong></p>

<p>[1] Zhu, Hao, et al. “EXCALIBUR: Encouraging and Evaluating Embodied Exploration.” Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023.</p>

<p>[2] Sharf, Jacob, Mustafa Omer Gul, and Yoav Artzi. “CB2: Collaborative Natural Language Interaction Research Platform.” arXiv preprint arXiv:2303.08127 (2023).</p>

<p>[3] Suhr, Alane, et al. “Executing instructions in situated collaborative interactions.” arXiv preprint arXiv:1910.03655 (2019).</p>

<p>[4] Deutsch, D. (2011). The beginning of infinity: Explanations that transform the world. New York: Viking.</p>

<p>[5] Blackmore Susan J. The Meme Machine. Oxford University Press 1999.</p>

<p>[6] Byrne RW. Imitation as behaviour parsing. Philos Trans R Soc Lond B Biol Sci. 2003 Mar 29;358(1431):529-36. doi: 10.1098/rstb.2002.1219. PMID: 12689378; PMCID: PMC1693132.</p>

<p>[7] Liu, Andy, et al. “Computational Language Acquisition with Theory of Mind.” arXiv preprint arXiv:2303.01502 (2023).</p>

<p>[8] Lazaridou, Angeliki, and Marco Baroni. “Emergent multi-agent communication in the deep learning era.” arXiv preprint arXiv:2006.02419 (2020).</p>

<p>[9] https://aeon.co/essays/how-close-are-we-to-creating-artificial-intelligence</p>

<p>[10] Nelli, Stephanie, et al. “Neural knowledge assembly in humans and neural networks.” Neuron 111.9 (2023): 1504-1516.</p>

<p>[11] Deniz, Fatma, et al. “Semantic representations during language comprehension are affected by context.” Journal of Neuroscience.</p>

<p>[12] Gong, Xue L., et al. “Phonemic segmentation of narrative speech in human cerebral cortex.” Nature Communications.</p>]]></content><author><name></name></author><category term="research" /><category term="research" /><summary type="html"><![CDATA[Some worthwhile research directions]]></summary></entry><entry><title type="html">You and your research/work/career</title><link href="https://tarun360.github.io/blog/2023/you-and-your-research/" rel="alternate" type="text/html" title="You and your research/work/career" /><published>2023-08-05T00:00:00+00:00</published><updated>2023-08-05T00:00:00+00:00</updated><id>https://tarun360.github.io/blog/2023/you-and-your-research</id><content type="html" xml:base="https://tarun360.github.io/blog/2023/you-and-your-research/"><![CDATA[<p>The ‘You and Your Research’ talk by Dr. Richard Hamming is a fantastic discussion applicable to careers in any field. One can watch it on YouTube <a href="https://youtu.be/a1zDuOPkMSw?si=K07WoHnMhQ8Nm1fR">here</a>. Dr. Hamming imparts great advice on envisioning your research or career and leading a purposeful life. Here I would like to share my thoughts on two specific ideas mentioned in this talk:</p>

<p><i>“If what you are working on is not important, and it’s not likely to lead to important things, then why are you working on it?”</i></p>

<p>This statement, and similar ideas about ‘meaningful work’, always make me ponder — what work should I really do? I certainly admit that my current software engineering job doesn’t quite measure up to the level of ‘meaningful work’ like drug discovery or rocket building. However, I console myself with the belief that I am building useful skills, preparing for a future where I can engage in work with tangible societal impact, rather than just making some enterprise messaging tool 10% faster. I have engaged in research during my undergrad, and while I am super proud of the work I have done, it’s certainly not in the top 1% category, far from it. Lately, I have been striving to make more meaningful contributions. For instance, I recently read a compelling paper about changing the incentive structure of social media platforms to combat fake news. The paper provided very practical, gamified solutions. After reading it, I had some ideas on how to extend it, and I emailed the authors with my thoughts. Well, that’s something. After all, ideas have infinite reach.</p>

<p><i>“Study your successes closely”</i></p>

<p>We often hear about learning from failures, but this was probably the first time I contemplated learning from successes. I recently experienced a kind of success, if one could call it that. I had spent 3-4 months tirelessly trying to secure a collaboration opportunity with an early-stage AI startup — countless hours (and headaches due to screen brightness) spent scraping sites like Y Combinator and LinkedIn to connect with early-stage AI startups. Didn’t get any success and eventually left it. A month after giving it a rest, a startup co-founder reached out to me with the opportunity I was seeking. It was quite serendipitous. This happened because during my previous search, I had interacted with a post on AI startups, and this co-founder found my profile through that interaction. It’s remarkable how, by reaching out and creating some entropy, one can potentially create luck for oneself. This was one of the motivations for sending the email mentioned above.</p>]]></content><author><name></name></author><category term="work" /><category term="work" /><summary type="html"><![CDATA[Thoughts from the famous talk "You and your research"]]></summary></entry><entry><title type="html">Provisional existence as a software engineer</title><link href="https://tarun360.github.io/blog/2023/provisional-existence/" rel="alternate" type="text/html" title="Provisional existence as a software engineer" /><published>2023-07-01T00:00:00+00:00</published><updated>2023-07-01T00:00:00+00:00</updated><id>https://tarun360.github.io/blog/2023/provisional-existence</id><content type="html" xml:base="https://tarun360.github.io/blog/2023/provisional-existence/"><![CDATA[<p>Sometime back I came across the quote “The days are long, but the years are short” by Gretchen Rubin and it immediately struck a chord with me. I checked its origin and found that it’s a parent adage implying that children grow up fast. But for me it somehow reminded me of my daily life as a software engineer. The days are long – meetings, debugging, some coding, and some more debugging. That stupid bug takes forever to fix, seemingly the most important thing in my life at the moment, but a week later I can’t even remember what it was.</p>

<p>Few months later, on re-reading the book <i>Man’s Search For Meaning</i> by Victor E. Frankl, I was drawn upon the idea of “provisional existence” – A man who is not able to see the end of his “provisional existence” ceases to have an ultimate aim in his life. The book mentions how Frankl’s fellow inmates in Germany’s concentration camps, having no idea when their liberation would happen, found their days longer than weeks. The book gives additional examples of how tuberculosis patients in a sanatorium having no fixed date of their release felt a similar phenomenon. I could relate this to my profession of software engineering at big tech companies. The daily tasks seem arduous and long, but the week goes by rather swiftly.</p>

<p>The entire promotion cycle within these big tech companies feels like a gamified and self-fulfilling endeavour. Moving from one level to another takes increasingly longer periods: approximately 1.5 years from L1 to L2, around 3 years from L2 to L3, then jumps of roughly 4 years, 6 years, and so on.The career growth is logarithmic; worse than linear. Stock options are structured in a way that there’s disproportionately more money in unvested stocks, incentivizing employees to stay longer; exemplifying the principle of loss aversion. Everything Is designed to keep individuals on the hedonic treadmill, with no discernible end date — just a perpetual cycle.</p>

<p>To be sure, software engineering is one of the cushiest jobs available right now in India, and I believe elsewhere as well. It offers excellent pay and favourable working conditions. The problem seems to me, as Victor Frankl puts it, means to live but no meaning. <a href="https://www.jointaro.com/question/PeIMgVaRQj8sToE44qqr/i-feel-destined-for-mediocrity-is-there-a-way-out/">This post</a> by a senior software engineer at Pinterest seems to be a common phenomenon. This is something which I actively notice in myself and my colleagues as well. People consciously or unconsciously try to combat it in different ways.</p>

<p>Some choose to slog longer hours in pursuit of additional responsibilities, finding meaning in mentoring or managing new employees. Others seek solace in luxurious experiences, dining at expensive restaurants or embarking on foreign vacations to Europe. Some distract themselves with video games like DOTA or CSGO. Then there are those who opt to switch careers, with product management being a popular choice, or venture into entrepreneurship.</p>]]></content><author><name></name></author><category term="personal" /><category term="psych" /><summary type="html"><![CDATA[Insights after working as a software engineer for 1 year.]]></summary></entry></feed>